{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae886f0b-53d5-46c6-a5f2-42408ced425e",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/ahmedgaitani/imdb-simple-rnn-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec295957-9b1b-46f7-ad18-84fdda8dd246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9001cbfc-c28d-4c81-af5b-d4e42afc5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab468e8-00ad-4c97-8576-f0f6dbc5b57b",
   "metadata": {},
   "source": [
    "pandas and numpy: Used for data manipulation and numerical operations.\n",
    "\n",
    "tensorflow: Deep learning library used to build and train the RNN model.\n",
    "\n",
    "sklearn: Used for splitting the dataset and calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990ed10e-34a6-49fe-b13c-0050f0d67dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('E:\\Python code\\IBM 文本分类数据')\n",
    "\n",
    "file_name = 'IMDB Dataset.csv'\n",
    "df = pd.read_csv(file_name)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44dd9d-e92c-4784-8556-1503e5384d65",
   "metadata": {},
   "source": [
    "Preprocessing the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a3be45-fd8f-4e05-b218-3480b9872019",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df['review'].values\n",
    "labels = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e05f29-c85d-4710-bf66-d336126d7e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb74f012-1bb1-4b17-acd5-9d132441d1c2",
   "metadata": {},
   "source": [
    "Tokenization and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9eea8bd-f74a-425f-ad56-3a0785863d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6452634b-9631-417c-8c17-fddfabd2769c",
   "metadata": {},
   "source": [
    "Tokenizer: Converts text into sequences of integers, where each integer represents a word in the vocabulary.\n",
    "\n",
    "num_words=5000: Limits the tokenizer to the top 10,000 most frequent words.\n",
    "\n",
    "fit_on_texts: Learns the vocabulary from the sentences.\n",
    "\n",
    "texts_to_sequences: Transforms each review into a sequence of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0eefeca-30b7-41ee-be8c-6af7d9c6357e",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X = pad_sequences(sequences, maxlen=maxlen)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d108031-9bad-40ac-90cb-852cccdd3d51",
   "metadata": {},
   "source": [
    "Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06bee5ff-53a8-4d8f-bd19-bd404e109d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfffc4a3-dce4-47c8-a5e3-9de09c8d060a",
   "metadata": {},
   "source": [
    "Building the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d01160f9-d7f6-4403-84f8-045a06183d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128))\n",
    "model.add(SimpleRNN(64, return_sequences=False, \n",
    "               kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(32, activation='relu', \n",
    "                kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14327368-5a2a-46df-a0d8-828f4dad01a6",
   "metadata": {},
   "source": [
    "Sequential(): Initializes a linear stack of layers for the model.\n",
    "\n",
    "Embedding(input_dim=5000, output_dim=128): Maps 5,000 unique words to dense 128-dimensional vectors.\n",
    "\n",
    "SimpleRNN(64, return_sequences=False): Adds a Simple RNN layer with 64 units and applies L2 regularization to reduce overfitting.\n",
    "\n",
    "Dropout(0.7): Drops 70% of the neurons randomly during training to prevent overfitting.\n",
    "\n",
    "Dense(32, activation='relu'): Adds a fully connected layer with 32 units, ReLU activation, and L2 regularization.\n",
    "\n",
    "Dense(1, activation='sigmoid'): Adds an output layer with 1 unit for binary classification using sigmoid activation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c12222-01c0-4972-a261-44dadbe09ec3",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "165feac8-5116-4625-b2ee-6cc7838d9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab304fe-0b12-4be5-b0ab-4f3b7ae22728",
   "metadata": {},
   "source": [
    "optimizer=Adam(learning_rate=0.0001): Uses the Adam optimizer with a learning rate of 0.0001 for efficient gradient descent.\n",
    "\n",
    "loss='binary_crossentropy': Loss function for binary classification.\n",
    "\n",
    "metrics=['accuracy']: Tracks the accuracy during training and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645fdb12-25e9-4589-8651-d2ed9d3de412",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7deca07-f7ff-4799-98ae-1e95b27f4065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 62ms/step - accuracy: 0.4977 - loss: 1.8847 - val_accuracy: 0.5838 - val_loss: 1.5753\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 61ms/step - accuracy: 0.5597 - loss: 1.4946 - val_accuracy: 0.7417 - val_loss: 1.2384\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.7245 - loss: 1.1773 - val_accuracy: 0.8365 - val_loss: 0.9336\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 58ms/step - accuracy: 0.8202 - loss: 0.9286 - val_accuracy: 0.8390 - val_loss: 0.7774\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.8623 - loss: 0.7563 - val_accuracy: 0.8553 - val_loss: 0.6527\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.8808 - loss: 0.6417 - val_accuracy: 0.8715 - val_loss: 0.5571\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.8906 - loss: 0.5563 - val_accuracy: 0.8562 - val_loss: 0.5329\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.8988 - loss: 0.4954 - val_accuracy: 0.8705 - val_loss: 0.4693\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 59ms/step - accuracy: 0.9044 - loss: 0.4505 - val_accuracy: 0.8716 - val_loss: 0.4451\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9118 - loss: 0.4151 - val_accuracy: 0.8737 - val_loss: 0.4221\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                               patience=3, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=10, batch_size=128, \n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab50a6-25c0-4a0b-aad5-c117b2564f0f",
   "metadata": {},
   "source": [
    "EarlyStopping(monitor='val_loss'): Monitors the validation loss during training and stops if it doesn't improve.\n",
    "\n",
    "patience=3: Stops training if the validation loss doesn't improve for 3 consecutive epochs.\n",
    "\n",
    "fit: Trains the model using the training data. The validation data is used to evaluate the model during training.\n",
    "\n",
    "epochs=10: The model will go through the entire dataset 10 times.\n",
    "\n",
    "batch_size=128: The number of samples processed before the model is updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0627ef80-e730-4855-aa1f-0cfa3f7d1b6c",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9bd7e4a-3f0e-4724-bc35-5e4a1e670d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8748 - loss: 0.4188\n",
      "Test Accuracy: 0.8737\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d32323b-9fa4-43c3-808b-1cc04f33c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n",
      "Accuracy Score: 0.8737\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(f'Accuracy Score: {accuracy_score(y_test, y_pred):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102652d9-4b57-4e16-aa3e-be7f148c6be4",
   "metadata": {},
   "source": [
    "predict: Generates predictions for the test data.\n",
    "\n",
    "y_pred: Converts probabilities to binary predictions (0 or 1).\n",
    "\n",
    "accuracy_score: Computes the accuracy between the true labels and the predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8489f2-4eb6-4028-b656-e1524fbc7da2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
