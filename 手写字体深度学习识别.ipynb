{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44a71999-f87f-43f9-8e86-53044f91175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01bdcc64-c187-4b4f-9f96-1a9eddcaaa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18f947c2-74d4-4265-88a9-6714c6c2cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e2d2342-6c6b-457b-9e14-7528cd90fc07",
   "metadata": {},
   "source": [
    "transform = transformers.Compose(\n",
    "    [ transforms.Resize(size), transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))]) # 正则化处理，相当于z-score\n",
    "\n",
    "trainset = MNIST(root = './', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = MNIST(root = './', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36f973-7ba2-480f-a41b-633bd885e8c7",
   "metadata": {},
   "source": [
    "# 1. 数据集准备\n",
    "\n",
    "手写数字识别的经典数据集是MNIST，它包含了28x28像素的手写数字图像。我们将使用Python的tensorflow库来加载和预览MNIST数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e780e71-ae2d-4e3e-a998-b5d77c961fa9",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/oandy0/article/details/137654041?ops_request_misc=&request_id=&biz_id=102&utm_term=%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%ABpython&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-1-137654041.142^v100^pc_search_result_base9&spm=1018.2226.3001.4187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6aeb9bf-a24d-48ac-a4eb-f2ccdb54cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78da9219-836e-49dc-b54e-bab100aac932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pylab as plt\n",
    "# 加载MNIST数据集\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# 显示一些训练数据\n",
    "for i in range(5):\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.axis('off')\n",
    "    plt.title(y_train[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e31935-a83c-45c6-a1ae-0c1dc1abad95",
   "metadata": {},
   "source": [
    "# 2. 数据预处理\n",
    "\n",
    "在训练神经网络之前，我们需要对数据进行预处理，包括归一化、划分训练集和测试集等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae244a1c-0da7-410f-b4ff-b2492d59c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据归一化\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "# 划分训练集和测试集\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "# 转换为4维张量\n",
    "x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "x_val = x_val.reshape(-1, 28, 28, 1)\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67c9bbf-8e28-4f13-a861-2de0bc3496cf",
   "metadata": {},
   "source": [
    "# 3. 构建神经网络\n",
    "\n",
    "我们将构建一个简单的神经网络，它包括一个输入层、两个隐藏层和一个输出层。每个隐藏层都使用ReLU激活函数，输出层使用softmax激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe20cfd5-2223-41e9-bcfe-6358e10d6474",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 构建神经网络\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "26019d7c-be97-4104-b7ca-708eeb2d725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.8802 - loss: 0.3935 - val_accuracy: 0.9763 - val_loss: 0.0746\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9839 - loss: 0.0536 - val_accuracy: 0.9827 - val_loss: 0.0570\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9887 - loss: 0.0368 - val_accuracy: 0.9857 - val_loss: 0.0460\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9922 - loss: 0.0270 - val_accuracy: 0.9808 - val_loss: 0.0683\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0221 - val_accuracy: 0.9902 - val_loss: 0.0356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1b9348eed90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f507e4-7239-4e71-bf8d-595861abc30a",
   "metadata": {},
   "source": [
    "5. 评估模型\n",
    "训练完成后，我们将使用测试数据来评估模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a67421-5c34-4c70-8e6d-702d5ee04b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 2ms/step - accuracy: 0.9909 - loss: 0.0292\n",
      "Test accuracy: 0.9908999800682068\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770d028-2dee-4b33-95dd-6c93d746abd0",
   "metadata": {},
   "source": [
    "6. 预测\n",
    "最后，我们可以使用模型来预测新的手写数字图像。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62d53a20-aac6-4724-b486-710904e0f76d",
   "metadata": {},
   "source": [
    "# 加载新的图像\n",
    "img = cv2.imread('path_to_new_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (28, 28))\n",
    "img = img.reshape(-1, 28, 28, 1)\n",
    "# 预测新图像\n",
    "prediction = model.predict(img)\n",
    "# 打印预测结果\n",
    "print(prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7c698-3ed2-4728-830f-a599b1b2ca53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afff983-2e8d-4fc4-ab22-bd453f83a71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e2944f-ec8a-447d-8f08-e496a55e5167",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/weixin_43718786/article/details/115252637?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522172422771916800188515887%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=172422771916800188515887&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-115252637-null-null.142^v100^pc_search_result_base9&utm_term=%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%ABpython&spm=1018.2226.3001.4187"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8b2caff-a33e-49bf-a691-cdaf0be25e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d402c0f0-0326-49d2-abc4-6127f9385fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5 # 模型训练5轮\n",
    "log_interval = 30 #控制打印频率的，设n = 30*batch_size，即n张图后打印一次进度\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 根据设备是否支持GPU来选择硬件 \n",
    "size = 32 # 对输入图片进行处理，拉伸为32*32的图片，这是为了复刻手写数字识别的神经网络，其输入为32*32的灰度图像\n",
    "learn_rate = 0.03 # 学习率\n",
    "momentum = 0.1  # 动量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f00ffc96-b512-46ec-81fd-8fe47a91e82c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'Resize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MNIST\n\u001b[0;32m      4\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[1;32m----> 5\u001b[0m     [ transforms\u001b[38;5;241m.\u001b[39mResize(size), transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      6\u001b[0m      transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m))]) \u001b[38;5;66;03m# 正则化处理，相当于z-score\u001b[39;00m\n\u001b[0;32m      8\u001b[0m trainset \u001b[38;5;241m=\u001b[39m MNIST(root \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[0;32m      9\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(trainset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torchvision.transforms' has no attribute 'Resize'"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [ transforms.Resize(size), transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5), (0.5))]) # 正则化处理，相当于z-score\n",
    "\n",
    "trainset = MNIST(root = './', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = MNIST(root = './', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eb0978-54f1-42c4-aa8e-5f1786125f46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6626764-c806-420e-aada-779808b6fe9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333e5921-629e-47f8-a61a-4bb6993b928d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b201e-dfe3-464a-b221-a7cddd7a0697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f45a89-f4d0-4051-b073-da83b42eb625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8dea7-309b-4062-b92b-d53dc4a2d0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff567acb-c965-49d5-9e29-08eea08744b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88f1adf-0e28-4860-9b59-d277a83aa322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712906aa-21a2-4049-8446-562c6049c5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5e6e21-81d2-4d39-a32b-12163b121940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b360e3-d73f-4f58-b69e-da393149c2d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
