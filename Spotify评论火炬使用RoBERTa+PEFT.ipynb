{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f0a7b8-b461-4b47-8d41-16922da4a92e",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/stpeteishii/spotify-review-torch-roberta-peft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf4c4cf-a96e-4199-bd02-cf15e7532540",
   "metadata": {},
   "source": [
    "# 关于PEFT\n",
    "\n",
    "PEFT（参数高效微调）是一种用于机器学习的技术，特别是在为特定任务微调大型预训练模型（如变压器（如BERT、GPT等）的情况下。PEFT的主要目标是减少在微调过程中需要更新的参数数量，这大大降低了计算成本和内存使用，同时保持甚至提高了性能"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4781be0-5f2d-4c34-9fa9-2210fdc3ec81",
   "metadata": {},
   "source": [
    "# PEFT的核心概念：\n",
    "\n",
    "效率：通过只关注一部分参数，PEFT避免了微调模型所有参数的需要，使过程更快，资源密集度更低。\n",
    "内存和计算节省：PEFT大大减少了所需的GPU内存量，使在较小的硬件设置上微调非常大的模型成为可能。\n",
    "性能维护：尽管微调的参数较少，但PEFT技术通常能够实现与完全微调相当甚至更优的性能。\n",
    "应用领域：PEFT广泛应用于自然语言处理（NLP）、计算机视觉和其他涉及大规模模型的人工智能任务，允许通用模型有效地适应特定应用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f572663d-861b-4127-ac84-174cb4b4a22b",
   "metadata": {},
   "source": [
    "# PEFT中使用的技术：¶\n",
    "适配器：插入预训练模型各层的小型神经网络模块，在不改变主模型权重的情况下学习特定任务的信息。\n",
    "低秩自适应（LoRA）：一种对模型权重的低秩更新进行微调的方法，减少了需要训练的参数数量。\n",
    "前缀调整：将特定于任务的向量（前缀）添加到影响模型输出的输入序列中，从而在不改变其核心参数的情况下调整模型。\n",
    "BitFit（仅偏置微调）：仅微调模型的偏置项，不影响大多数权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a3d89e6-ab3c-420a-b23b-883942fdb86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import transformers\n",
    "import random\n",
    "import chardet\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a0df049-7d46-4a62-bc39-68583c220a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(SEED):\n",
    "    \n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "SEED = 508\n",
    "random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f66cb87-2537-477f-bdb6-2ed9d100d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r'E:\\Python code\\Spotify用户评论')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97bd11a4-86a6-466f-b6db-4463c7a6d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36615</th>\n",
       "      <td>What is happening! Spotify will randomly start...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41766</th>\n",
       "      <td>Some of my songs are not downloaded and i dont...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>There should be an option to edit home screen</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27751</th>\n",
       "      <td>I love Spotify for the large catalogue and the...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22981</th>\n",
       "      <td>Its so cool so far the best app i found for fr...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25867</th>\n",
       "      <td>The app quits by itself and restarts by itself...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47692</th>\n",
       "      <td>Just constantly recommending podcasts to me de...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9590</th>\n",
       "      <td>Keeps crashing piece of sh</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20563</th>\n",
       "      <td>The app is super glitchy. Currently 1 title is...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46065</th>\n",
       "      <td>It added extra songs to my playlist and I didn...</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review     label\n",
       "36615  What is happening! Spotify will randomly start...  NEGATIVE\n",
       "41766  Some of my songs are not downloaded and i dont...  NEGATIVE\n",
       "5708       There should be an option to edit home screen  NEGATIVE\n",
       "27751  I love Spotify for the large catalogue and the...  POSITIVE\n",
       "22981  Its so cool so far the best app i found for fr...  POSITIVE\n",
       "...                                                  ...       ...\n",
       "25867  The app quits by itself and restarts by itself...  NEGATIVE\n",
       "47692  Just constantly recommending podcasts to me de...  NEGATIVE\n",
       "9590                          Keeps crashing piece of sh  POSITIVE\n",
       "20563  The app is super glitchy. Currently 1 title is...  NEGATIVE\n",
       "46065  It added extra songs to my playlist and I didn...  POSITIVE\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=pd.read_csv('DATASET.csv')\n",
    "data=data.dropna()\n",
    "n=len(data)\n",
    "N=list(range(n))\n",
    "random.shuffle(N)\n",
    "data=data.iloc[N[0:5000]]\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65db3970-ec22-434c-b030-950477108556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEGATIVE', 'POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "data.columns=['text','label']\n",
    "class_names=sorted(data['label'].unique().tolist())\n",
    "print(class_names)\n",
    "N=list(range(len(class_names)))\n",
    "normal_mapping=dict(zip(class_names,N)) \n",
    "reverse_mapping=dict(zip(N,class_names))       \n",
    "data['label']=data['label'].map(normal_mapping) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a41e5db-70e3-4c27-b703-0b23adf322ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b76342e7-633c-47b3-b2e3-f016206341d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ea385626294ded9f5a3edf937c852b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f770e3790c941fbbb680a3019e6e361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1779e40321407b9da6dabb87c2fd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a509ea20cabe4061b6d73fcbc238a387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1899c1796bc44272a9487cdbf65760f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n",
    "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c76bc11-b7f2-4fa0-89f1-8010077297e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Learning to love it! â\\x9d¤</s>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s = train['text'].iloc[0]\n",
    "\n",
    "result1 = tokenizer.encode_plus(test_s)\n",
    "\n",
    "tokenizer.decode(result1[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9802fdc5-ba41-440c-b167-cebb319c1fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_s.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b57f549-675b-443e-9e8d-70ef60d5830e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Learning to love it! â\\x9d¤</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = tokenizer.encode_plus(\n",
    "    test_s,\n",
    "    add_special_tokens = True, \n",
    "    max_length = 32, \n",
    "    pad_to_max_length = True, \n",
    "    truncation = True \n",
    ")\n",
    "tokenizer.decode(result2[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc3b9913-3028-4d4d-abf9-a5645dce38d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sens = 32\n",
    "\n",
    "train = train.sort_values(\"label\").reset_index(drop=True)\n",
    "\n",
    "train[\"kfold\"] = train.index % 5\n",
    "\n",
    "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
    "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
    "\n",
    "p_test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3bca2a9-a6ba-4237-96b8-05c2f7df490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataSet(Dataset):\n",
    "    #__len__ 方法定义了数据集的长度，而 __getitem__ 方法定义了如何访问数据集中的单个样本。\n",
    "    def __init__(self,sentences,targets):        \n",
    "        self.sentences = sentences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):#__len__ 方法返回 self.sentences 的长度        \n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,idx):#这个方法定义了如何通过索引来获取数据集中的单个元素。当你尝试访问 dataset_instance[i] 时（其中 i 是索引），就会调用这个方法。        \n",
    "        sentence = self.sentences[idx]    \n",
    "        bert_sens = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                add_special_tokens = True, \n",
    "                                max_length = max_sens, \n",
    "                                pad_to_max_length = True, \n",
    "                                return_attention_mask = True)\n",
    "\n",
    "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "\n",
    "                'targets': target\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b4bd869-2314-4435-b234-8d2b4dd910a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BERTDataSet(p_train[\"text\"],p_train[\"label\"])\n",
    "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid[\"label\"])\n",
    "test_dataset = BERTDataSet(p_test[\"text\"],p_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5037e735-7278-40c8-8b68-c80e92a7381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 16\n",
    "valid_batch = 32\n",
    "test_batch = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfb6e7da-6abd-4f5d-a142-4ecaaa499d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd9937e31fb24a55801a294553f94c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
    "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad4fdca-5d60-4cfe-8dd3-ac7d13ede129",
   "metadata": {},
   "source": [
    "peft setting for roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a207b3-4fe8-4bac-87b4-1bbfa60b190c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#peft setting for roberta\n",
    "\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, TaskType\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,   \n",
    "    inference_mode=False,        \n",
    "    r=8,                          \n",
    "    lora_alpha=16,             \n",
    "    lora_dropout=0.1              \n",
    ")\n",
    "\n",
    "lora_model = get_peft_model(model, lora_config)\n",
    "model = lora_model\n",
    "display(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea241c2a-89ff-4854-9dad-6629c2c130fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (value): Linear(\n",
       "                    in_features=768, out_features=768, bias=True\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb718df-9c16-4518-88fb-399ba95ac045",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in train_dataloader:\n",
    "    ids = a[\"ids\"].to(device)\n",
    "    mask = a[\"mask\"].to(device)\n",
    "\n",
    "    output = model(ids,mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a298e-0bc5-4cc1-8e25-716994e5b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[\"logits\"].squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f41b07-c2c0-49e6-9222-3e52bd9eb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "LR=2e-5\n",
    "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf93655b-2c22-4fb3-acc3-7a1c443734c3",
   "metadata": {},
   "source": [
    "set epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6124d00b-0003-4ad7-85fd-2ce9bd761750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 10\n",
    "4\n",
    "#if debug:\n",
    "#    epochs = 1\n",
    "\n",
    "train_steps = int(len(p_train)/train_batch*epochs)\n",
    "print(train_steps)\n",
    "num_steps = int(train_steps*0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
    "\n",
    "def loss_fn(output,target):\n",
    "    return torch.sqrt(nn.MSELoss()(output,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982840ad-43a3-48be-9fd1-f0fbd0deb1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066f6965-23f4-4bb9-89b9-a6a76dd7d5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0783c-444f-4bd6-8550-a137afe4d87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a498240-68d6-4754-856d-21e79528c410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceeb3aa-7f0a-469c-8d24-4b0c21beb0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
