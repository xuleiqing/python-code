{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88be5a6a-2b02-4aed-b833-10b675a2383d",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/konradb/ts-10-validation-methods-for-time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2880b5e-446a-4c2f-bb05-f8f23100172e",
   "metadata": {},
   "source": [
    "除了那些因为YOLO而在周五晚上部署到生产环境的人之外，我们都同意模型验证很重要：测量机器学习模型的性能（以及它的泛化能力）使我们能够评估鲁棒性，优化参数并估计看不见的数据的性能。如果有充分的理由相信底层数据生成过程是平稳的（没有概念漂移），那么你通常可以接受训练验证测试分割（尽管对验证集过拟合）。如果时间维度很重要，情况会变得稍微复杂一些：在这一集中，我们将在不打破时间箭头的情况下，介绍评估时间序列模型性能的不同方式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aa4cbe16-0b35-406d-94f5-b0795219cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "from scipy.stats import pearsonr as p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight') \n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category= FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f7104-e137-4662-9e6c-c73430776385",
   "metadata": {},
   "source": [
    "# 随机拆分¶\n",
    "我们将使用最近结束的Ubiquant市场预测竞赛的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03cab58a-f450-4ece-8e60-b2b087b5504c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0_1062</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>-0.468671</td>\n",
       "      <td>-0.706653</td>\n",
       "      <td>-0.765238</td>\n",
       "      <td>0.620830</td>\n",
       "      <td>-0.581358</td>\n",
       "      <td>0.993605</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.169476</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>0.464294</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>0.540411</td>\n",
       "      <td>0.375438</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>0_1144</td>\n",
       "      <td>0</td>\n",
       "      <td>1144</td>\n",
       "      <td>-0.107676</td>\n",
       "      <td>-0.748410</td>\n",
       "      <td>-2.271974</td>\n",
       "      <td>0.381967</td>\n",
       "      <td>-0.581879</td>\n",
       "      <td>-0.606941</td>\n",
       "      <td>0.703325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>-0.633994</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.669425</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.303525</td>\n",
       "      <td>-1.861270</td>\n",
       "      <td>-0.815836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>0_2140</td>\n",
       "      <td>0</td>\n",
       "      <td>2140</td>\n",
       "      <td>-0.824360</td>\n",
       "      <td>0.876086</td>\n",
       "      <td>-1.769729</td>\n",
       "      <td>-0.230321</td>\n",
       "      <td>-0.579754</td>\n",
       "      <td>-0.366735</td>\n",
       "      <td>0.240823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>-0.654613</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.503797</td>\n",
       "      <td>1.296864</td>\n",
       "      <td>-0.862824</td>\n",
       "      <td>-1.492674</td>\n",
       "      <td>-0.418889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>0_2385</td>\n",
       "      <td>0</td>\n",
       "      <td>2385</td>\n",
       "      <td>0.282452</td>\n",
       "      <td>0.217906</td>\n",
       "      <td>-1.141922</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>-0.576741</td>\n",
       "      <td>2.127874</td>\n",
       "      <td>0.175264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-1.119840</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>0.136213</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>1.146075</td>\n",
       "      <td>-1.286455</td>\n",
       "      <td>0.538988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>0_2727</td>\n",
       "      <td>0</td>\n",
       "      <td>2727</td>\n",
       "      <td>-0.736424</td>\n",
       "      <td>-0.928419</td>\n",
       "      <td>3.001602</td>\n",
       "      <td>-1.925446</td>\n",
       "      <td>1.215150</td>\n",
       "      <td>1.979153</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.105698</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>-0.648119</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>1.251450</td>\n",
       "      <td>1.296864</td>\n",
       "      <td>0.412373</td>\n",
       "      <td>1.431981</td>\n",
       "      <td>2.084112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>1_1062</td>\n",
       "      <td>1</td>\n",
       "      <td>1062</td>\n",
       "      <td>-0.223018</td>\n",
       "      <td>-0.805850</td>\n",
       "      <td>-0.814999</td>\n",
       "      <td>0.723359</td>\n",
       "      <td>-0.608408</td>\n",
       "      <td>0.982574</td>\n",
       "      <td>0.235933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693888</td>\n",
       "      <td>0.924511</td>\n",
       "      <td>0.082710</td>\n",
       "      <td>-1.721066</td>\n",
       "      <td>-1.189598</td>\n",
       "      <td>0.011736</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>-0.838125</td>\n",
       "      <td>-0.766690</td>\n",
       "      <td>0.002693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>1_1144</td>\n",
       "      <td>1</td>\n",
       "      <td>1144</td>\n",
       "      <td>0.557137</td>\n",
       "      <td>-0.779184</td>\n",
       "      <td>-2.173314</td>\n",
       "      <td>0.353022</td>\n",
       "      <td>-0.610101</td>\n",
       "      <td>-0.597564</td>\n",
       "      <td>0.413387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167517</td>\n",
       "      <td>-1.081652</td>\n",
       "      <td>-1.077176</td>\n",
       "      <td>-1.721066</td>\n",
       "      <td>-1.189598</td>\n",
       "      <td>-0.698124</td>\n",
       "      <td>-1.173816</td>\n",
       "      <td>-0.468102</td>\n",
       "      <td>-1.912625</td>\n",
       "      <td>-0.831070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>1_2140</td>\n",
       "      <td>1</td>\n",
       "      <td>2140</td>\n",
       "      <td>-0.012454</td>\n",
       "      <td>0.951884</td>\n",
       "      <td>-1.802864</td>\n",
       "      <td>-0.211035</td>\n",
       "      <td>-0.608806</td>\n",
       "      <td>-0.372428</td>\n",
       "      <td>0.778097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.746629</td>\n",
       "      <td>-1.081652</td>\n",
       "      <td>-0.181377</td>\n",
       "      <td>-1.721066</td>\n",
       "      <td>0.839101</td>\n",
       "      <td>-0.491055</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>-0.943950</td>\n",
       "      <td>-0.992202</td>\n",
       "      <td>-0.432896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>1_2385</td>\n",
       "      <td>1</td>\n",
       "      <td>2385</td>\n",
       "      <td>0.864889</td>\n",
       "      <td>0.739182</td>\n",
       "      <td>-1.185449</td>\n",
       "      <td>0.103720</td>\n",
       "      <td>-0.605656</td>\n",
       "      <td>2.109318</td>\n",
       "      <td>-0.808031</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341965</td>\n",
       "      <td>0.924511</td>\n",
       "      <td>-1.039949</td>\n",
       "      <td>0.581035</td>\n",
       "      <td>0.839101</td>\n",
       "      <td>0.734250</td>\n",
       "      <td>0.027711</td>\n",
       "      <td>1.556703</td>\n",
       "      <td>-1.654856</td>\n",
       "      <td>0.739229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3930</th>\n",
       "      <td>1_2727</td>\n",
       "      <td>1</td>\n",
       "      <td>2727</td>\n",
       "      <td>0.278300</td>\n",
       "      <td>0.868855</td>\n",
       "      <td>2.889494</td>\n",
       "      <td>-1.982309</td>\n",
       "      <td>1.506996</td>\n",
       "      <td>2.033059</td>\n",
       "      <td>-0.112873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.341965</td>\n",
       "      <td>-1.081652</td>\n",
       "      <td>-0.050472</td>\n",
       "      <td>0.581035</td>\n",
       "      <td>0.839101</td>\n",
       "      <td>1.223184</td>\n",
       "      <td>1.229239</td>\n",
       "      <td>1.310940</td>\n",
       "      <td>1.565812</td>\n",
       "      <td>2.147083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_id  time_id  investment_id    target       f_0       f_1       f_2  \\\n",
       "652   0_1062        0           1062 -0.468671 -0.706653 -0.765238  0.620830   \n",
       "705   0_1144        0           1144 -0.107676 -0.748410 -2.271974  0.381967   \n",
       "1294  0_2140        0           2140 -0.824360  0.876086 -1.769729 -0.230321   \n",
       "1445  0_2385        0           2385  0.282452  0.217906 -1.141922  0.399086   \n",
       "1659  0_2727        0           2727 -0.736424 -0.928419  3.001602 -1.925446   \n",
       "2924  1_1062        1           1062 -0.223018 -0.805850 -0.814999  0.723359   \n",
       "2976  1_1144        1           1144  0.557137 -0.779184 -2.173314  0.353022   \n",
       "3568  1_2140        1           2140 -0.012454  0.951884 -1.802864 -0.211035   \n",
       "3717  1_2385        1           2385  0.864889  0.739182 -1.185449  0.103720   \n",
       "3930  1_2727        1           2727  0.278300  0.868855  2.889494 -1.982309   \n",
       "\n",
       "           f_3       f_4       f_5  ...     f_290     f_291     f_292  \\\n",
       "652  -0.581358  0.993605  0.408986  ... -0.170365  0.912726 -0.169476   \n",
       "705  -0.581879 -0.606941  0.703325  ...  0.821560 -1.095620 -0.633994   \n",
       "1294 -0.579754 -0.366735  0.240823  ...  0.821560 -1.095620 -0.654613   \n",
       "1445 -0.576741  2.127874  0.175264  ... -0.170365  0.912726 -1.119840   \n",
       "1659  1.215150  1.979153  1.603922  ... -2.105698 -1.095620 -0.648119   \n",
       "2924 -0.608408  0.982574  0.235933  ...  0.693888  0.924511  0.082710   \n",
       "2976 -0.610101 -0.597564  0.413387  ...  0.167517 -1.081652 -1.077176   \n",
       "3568 -0.608806 -0.372428  0.778097  ...  1.746629 -1.081652 -0.181377   \n",
       "3717 -0.605656  2.109318 -0.808031  ... -0.341965  0.924511 -1.039949   \n",
       "3930  1.506996  2.033059 -0.112873  ... -0.341965 -1.081652 -0.050472   \n",
       "\n",
       "         f_293     f_294     f_295     f_296     f_297     f_298     f_299  \n",
       "652  -1.220772  0.941183  0.464294 -1.087009  0.540411  0.375438  0.003703  \n",
       "705  -1.220772  0.941183 -0.669425  0.104928 -0.303525 -1.861270 -0.815836  \n",
       "1294 -1.220772  0.941183 -0.503797  1.296864 -0.862824 -1.492674 -0.418889  \n",
       "1445  0.819155  0.941183  0.136213  0.104928  1.146075 -1.286455  0.538988  \n",
       "1659  0.819155 -1.060166  1.251450  1.296864  0.412373  1.431981  2.084112  \n",
       "2924 -1.721066 -1.189598  0.011736  0.027711 -0.838125 -0.766690  0.002693  \n",
       "2976 -1.721066 -1.189598 -0.698124 -1.173816 -0.468102 -1.912625 -0.831070  \n",
       "3568 -1.721066  0.839101 -0.491055  0.027711 -0.943950 -0.992202 -0.432896  \n",
       "3717  0.581035  0.839101  0.734250  0.027711  1.556703 -1.654856  0.739229  \n",
       "3930  0.581035  0.839101  1.223184  1.229239  1.310940  1.565812  2.147083  \n",
       "\n",
       "[10 rows x 304 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('E:\\python code\\量化交易数据')\n",
    "\n",
    "xtrain = pd.read_parquet(\"train_2.parquet\")\n",
    "xtrain.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54673a18-2a6d-4d75-b7d8-d833cc73e845",
   "metadata": {},
   "source": [
    "这个问题有很多特点，使其比平时更具挑战性：\n",
    "多项投资-并非所有投资都出现在每个时间戳\n",
    "（可能）时间戳之间的间隔不同\n",
    "试验期结束后未立即进行试验观察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfeed670-48e8-4697-9f95-dc268fd7456b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1219)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain['time_id'].min(), xtrain['time_id'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47916226-78de-44f7-908a-227493cf86b8",
   "metadata": {},
   "source": [
    "PSA：为了使设置真正正确，我们应该围绕这个块进行循环，并更改测试集\n",
    "→\n",
    "否则，我们就有过度拟合测试集的风险\n",
    "我们将保留从时间戳1100开始的观测值作为我们的坚持测试集，并尝试使用其余的观测值："
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1090e1d-5d42-49d4-904a-57b3d46aa682",
   "metadata": {},
   "source": [
    "# general settings\n",
    "class CFG:\n",
    "    data_folder = '../input/tsdata-1/'\n",
    "    img_dim1 = 20\n",
    "    img_dim2 = 10\n",
    "    seed = 13\n",
    "    nfolds = 5\n",
    "    nof_trees = 150\n",
    "    cutoff_point = 1100\n",
    "    \n",
    "# adjust the parameters for displayed figures    \n",
    "plt.rcParams.update({'figure.figsize': (CFG.img_dim1,CFG.img_dim2)})   "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c97af16d-ea7b-4081-ac51-6b9c0dc4a6e3",
   "metadata": {},
   "source": [
    "# train / validation split\n",
    "xtest = xtrain.loc[xtrain.time_id > CFG.cutoff_point].copy()\n",
    "xtrain = xtrain.loc[xtrain.time_id <= CFG.cutoff_point].copy()\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a8f81d3-f1c9-4be5-8257-7229e85baee2",
   "metadata": {},
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "62361362-8899-4a19-909d-0d3799b1d35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain.index= range(xtrain.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df2e6173-29ca-4f4d-b8d4-ebb9ae76b14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1062</td>\n",
       "      <td>0</td>\n",
       "      <td>1062</td>\n",
       "      <td>-0.468671</td>\n",
       "      <td>-0.706653</td>\n",
       "      <td>-0.765238</td>\n",
       "      <td>0.620830</td>\n",
       "      <td>-0.581358</td>\n",
       "      <td>0.993605</td>\n",
       "      <td>0.408986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.169476</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>0.464294</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>0.540411</td>\n",
       "      <td>0.375438</td>\n",
       "      <td>0.003703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_1144</td>\n",
       "      <td>0</td>\n",
       "      <td>1144</td>\n",
       "      <td>-0.107676</td>\n",
       "      <td>-0.748410</td>\n",
       "      <td>-2.271974</td>\n",
       "      <td>0.381967</td>\n",
       "      <td>-0.581879</td>\n",
       "      <td>-0.606941</td>\n",
       "      <td>0.703325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>-0.633994</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.669425</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.303525</td>\n",
       "      <td>-1.861270</td>\n",
       "      <td>-0.815836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_2140</td>\n",
       "      <td>0</td>\n",
       "      <td>2140</td>\n",
       "      <td>-0.824360</td>\n",
       "      <td>0.876086</td>\n",
       "      <td>-1.769729</td>\n",
       "      <td>-0.230321</td>\n",
       "      <td>-0.579754</td>\n",
       "      <td>-0.366735</td>\n",
       "      <td>0.240823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.821560</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>-0.654613</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.503797</td>\n",
       "      <td>1.296864</td>\n",
       "      <td>-0.862824</td>\n",
       "      <td>-1.492674</td>\n",
       "      <td>-0.418889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_2385</td>\n",
       "      <td>0</td>\n",
       "      <td>2385</td>\n",
       "      <td>0.282452</td>\n",
       "      <td>0.217906</td>\n",
       "      <td>-1.141922</td>\n",
       "      <td>0.399086</td>\n",
       "      <td>-0.576741</td>\n",
       "      <td>2.127874</td>\n",
       "      <td>0.175264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-1.119840</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>0.136213</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>1.146075</td>\n",
       "      <td>-1.286455</td>\n",
       "      <td>0.538988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_2727</td>\n",
       "      <td>0</td>\n",
       "      <td>2727</td>\n",
       "      <td>-0.736424</td>\n",
       "      <td>-0.928419</td>\n",
       "      <td>3.001602</td>\n",
       "      <td>-1.925446</td>\n",
       "      <td>1.215150</td>\n",
       "      <td>1.979153</td>\n",
       "      <td>1.603922</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.105698</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>-0.648119</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>1.251450</td>\n",
       "      <td>1.296864</td>\n",
       "      <td>0.412373</td>\n",
       "      <td>1.431981</td>\n",
       "      <td>2.084112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  time_id  investment_id    target       f_0       f_1       f_2  \\\n",
       "0  0_1062        0           1062 -0.468671 -0.706653 -0.765238  0.620830   \n",
       "1  0_1144        0           1144 -0.107676 -0.748410 -2.271974  0.381967   \n",
       "2  0_2140        0           2140 -0.824360  0.876086 -1.769729 -0.230321   \n",
       "3  0_2385        0           2385  0.282452  0.217906 -1.141922  0.399086   \n",
       "4  0_2727        0           2727 -0.736424 -0.928419  3.001602 -1.925446   \n",
       "\n",
       "        f_3       f_4       f_5  ...     f_290     f_291     f_292     f_293  \\\n",
       "0 -0.581358  0.993605  0.408986  ... -0.170365  0.912726 -0.169476 -1.220772   \n",
       "1 -0.581879 -0.606941  0.703325  ...  0.821560 -1.095620 -0.633994 -1.220772   \n",
       "2 -0.579754 -0.366735  0.240823  ...  0.821560 -1.095620 -0.654613 -1.220772   \n",
       "3 -0.576741  2.127874  0.175264  ... -0.170365  0.912726 -1.119840  0.819155   \n",
       "4  1.215150  1.979153  1.603922  ... -2.105698 -1.095620 -0.648119  0.819155   \n",
       "\n",
       "      f_294     f_295     f_296     f_297     f_298     f_299  \n",
       "0  0.941183  0.464294 -1.087009  0.540411  0.375438  0.003703  \n",
       "1  0.941183 -0.669425  0.104928 -0.303525 -1.861270 -0.815836  \n",
       "2  0.941183 -0.503797  1.296864 -0.862824 -1.492674 -0.418889  \n",
       "3  0.941183  0.136213  0.104928  1.146075 -1.286455  0.538988  \n",
       "4 -1.060166  1.251450  1.296864  0.412373  1.431981  2.084112  \n",
       "\n",
       "[5 rows x 304 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dee1eae4-5e2f-43b7-91dc-ca651c4c8f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5452, 304) (623, 304)\n"
     ]
    }
   ],
   "source": [
    "# general settings\n",
    "class CFG:\n",
    "    data_folder = '../input/tsdata-1/'\n",
    "    img_dim1 = 20\n",
    "    img_dim2 = 10\n",
    "    seed = 13\n",
    "    nfolds = 5\n",
    "    nof_trees = 150\n",
    "    cutoff_point = 1100\n",
    "    \n",
    "# adjust the parameters for displayed figures    \n",
    "plt.rcParams.update({'figure.figsize': (CFG.img_dim1,CFG.img_dim2)})   \n",
    "\n",
    "# train / validation split\n",
    "xtest = xtrain.loc[xtrain.time_id > CFG.cutoff_point].copy()\n",
    "xtrain = xtrain.loc[xtrain.time_id <= CFG.cutoff_point].copy()\n",
    "print(xtrain.shape, xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da1f468d-6f84-4672-ba73-8a136b394409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal cleanup and preparation\n",
    "\n",
    "id_train, id_test = xtrain['row_id'].copy(), xtest['row_id'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "234ca163-363c-486d-9055-a0878b97e09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 12.52 MB\n",
      "Memory usage after optimization is: 3.16 MB\n",
      "Decreased by 74.8%\n",
      "Memory usage of dataframe is 1.43 MB\n",
      "Memory usage after optimization is: 0.36 MB\n",
      "Decreased by 74.8%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.drop('row_id', axis = 1, inplace = True)\n",
    "xtest.drop('row_id', axis = 1, inplace = True)\n",
    "\n",
    "ytrain, ytest = xtrain['target'].copy(), xtest['target'].copy()\n",
    "inv_train, inv_test = xtrain['investment_id'].copy(), xtest['investment_id'].copy()\n",
    "time_train, time_test = xtrain['time_id'].copy(), xtest['time_id'].copy()\n",
    "\n",
    "xtrain.drop(['time_id', 'investment_id', 'target'], axis = 1, inplace = True)\n",
    "xtest.drop(['time_id', 'investment_id', 'target'], axis = 1, inplace = True)\n",
    "\n",
    "xtrain = reduce_mem_usage(xtrain)\n",
    "xtest = reduce_mem_usage(xtest)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8e28b659-afd0-4ad6-a756-83a104270a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x0, x1, y0, y1 = train_test_split(xtrain, ytrain, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce9366d9-84ef-4abb-a0c7-d4a60dfe83d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    }
   ],
   "source": [
    "lgb_parameters = {'objective': 'regression', 'metric': 'rmse', 'num_iterations': CFG.nof_trees, \n",
    "                          'num_leaves': 32, 'learning_rate': 0.1, 'subsample': 0.8, 'colsample_bytree': 0.6}\n",
    "\n",
    "model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "\n",
    "model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)], verbose= 250, early_stopping_rounds=100)\n",
    "val_preds = model.predict(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "724d7431-4d4c-4003-bea9-ce6e524eb5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.33\n",
      "test score: -0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validation score    \n",
    "score = np.round(p(val_preds, y1)[0],4)\n",
    "print(\"validation score: \" + str(score))\n",
    "\n",
    "\n",
    "# actual test performance\n",
    "test_preds = model.predict(xtest)\n",
    "score = np.round(p(test_preds, ytest)[0],4)\n",
    "print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "del x0, x1, y0, y1; gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affe6db1-d7bd-41d8-b230-9555ae14f3fb",
   "metadata": {},
   "source": [
    "# KFold¶\n",
    "A second most common approach to validation is KFold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcd67b5e-fe22-4d94-88b5-c74aa0fdd0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.3584\n",
      "test score: -0.0038\n",
      "fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.2983\n",
      "test score: -0.0038\n",
      "fold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.2688\n",
      "test score: -0.0038\n",
      "fold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.3195\n",
      "test score: -0.0038\n",
      "fold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.278\n",
      "test score: -0.0038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = CFG.nfolds,  shuffle = True, random_state = CFG.seed)\n",
    "res_vec = np.zeros((CFG.nfolds, 1))\n",
    "\n",
    "prv = np.zeros((xtest.shape[0],CFG.nfolds))\n",
    "\n",
    "for (ii, (id0, id1)) in enumerate(kf.split(xtrain)):\n",
    "    \n",
    "    print('fold: ' + str(ii))\n",
    "    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n",
    "    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "    model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)], verbose= 250, early_stopping_rounds=100)\n",
    "    val_preds = model.predict(x1)\n",
    "    prv[:,ii] += model.predict(xtest) / CFG.nfolds\n",
    "    \n",
    "    # validation score    \n",
    "    score = np.round(p(val_preds, y1)[0],4)\n",
    "    res_vec[ii] = score\n",
    "    print(\"validation score: \" + str(score))\n",
    "\n",
    "    # actual test performance\n",
    "    score = np.round(p(test_preds, ytest)[0],4)\n",
    "    print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "    del model, x0, x1, y0, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91ec85b2-14a8-4119-8469-81e1afb9c646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average score across folds: 0.3046\n",
      "full test score: 0.0108\n"
     ]
    }
   ],
   "source": [
    "avg_score = np.round(np.mean(res_vec),4)\n",
    "print(\"average score across folds: \" + str(avg_score))\n",
    "score = np.round(p(ytest, prv.mean(axis = 1))[0],4)\n",
    "\n",
    "print(\"full test score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c0e0c9-95b4-41be-99ee-3e690a945f56",
   "metadata": {},
   "source": [
    "# 时间序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65987c66-837a-4a68-a0e5-928929eb6149",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits = CFG.nfolds , max_train_size = None)\n",
    "\n",
    "res_vec = np.zeros((CFG.nfolds, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e8a6b6-262d-4679-9bd1-9268cea0e578",
   "metadata": {},
   "source": [
    "`from sklearn.model_selection import TimeSeriesSplit` 是在Python的`scikit-learn`库中的一个导入语句，它的作用是导入`TimeSeriesSplit`类。`TimeSeriesSplit`是`scikit-learn`中用于时间序列数据交叉验证的一个分割器。 在机器学习中，交叉验证是一种评估模型泛化能力的技术，它通过将数据集分割成多个小子集来工作，通常包括训练集和验证集（或测试集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "73bd18f0-066a-430e-ab6b-9fdb79a070b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: -0.0358\n",
      "test score: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0004\n",
      "test score: 0.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0317\n",
      "test score: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.1077\n",
      "test score: 0.0492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0936\n",
      "test score: 0.0656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for (ii, (id0, id1)) in enumerate(tscv.split(xtrain)):\n",
    "    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n",
    "    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "    model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)], verbose= 250, early_stopping_rounds=100)\n",
    "    val_preds = model.predict(x1)\n",
    "    prv[:,ii] += model.predict(xtest) / CFG.nfolds\n",
    "    \n",
    "    # validation score    \n",
    "    score = np.round(p(val_preds, y1)[0],4)\n",
    "    res_vec[ii] = score\n",
    "    print(\"validation score: \" + str(score))\n",
    "\n",
    "    # actual test performance\n",
    "    test_preds = model.predict(xtest)\n",
    "    score = np.round(p(test_preds, ytest)[0],4)\n",
    "    print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "    del model, x0, x1, y0, y1\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a41a281-5963-46cc-99b7-811c077fa738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: -0.0358\n",
      "test score: 0.0486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0645\n",
      "test score: -0.0521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0393\n",
      "test score: 0.0424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0861\n",
      "test score: 0.0063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0531\n",
      "test score: -0.0499\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits = CFG.nfolds , max_train_size = 2 * xtest.shape[0])\n",
    "\n",
    "res_vec = np.zeros((CFG.nfolds, 1))\n",
    "\n",
    "\n",
    "for (ii, (id0, id1)) in enumerate(tscv.split(xtrain)):\n",
    "    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n",
    "    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "    model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)], verbose= 250, early_stopping_rounds=100)\n",
    "    val_preds = model.predict(x1)\n",
    "    prv[:,ii] += model.predict(xtest) / CFG.nfolds\n",
    "    \n",
    "    # validation score    \n",
    "    score = np.round(p(val_preds, y1)[0],4)\n",
    "    res_vec[ii] = score\n",
    "    print(\"validation score: \" + str(score))\n",
    "\n",
    "    # actual test performance\n",
    "    test_preds = model.predict(xtest)\n",
    "    score = np.round(p(test_preds, ytest)[0],4)\n",
    "    print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "    del model, x0, x1, y0, y1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984ceb1-192b-487a-885f-607d37f39ddc",
   "metadata": {},
   "source": [
    "# WFV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7876c6e2-0394-4de0-a27f-69dab0b8b488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182]\n",
      "[365]\n",
      "[]\n",
      "[737]\n",
      "[919]\n"
     ]
    }
   ],
   "source": [
    "for train_idx, test_idx in TimeSeriesSplit().split(xtrain):\n",
    "    id1 = time_train.loc[train_idx].unique()\n",
    "    id2 = time_train.loc[test_idx].unique()\n",
    "    \n",
    "    print(np.intersect1d(id1,id2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4896b-a5be-40c6-8b05-1ab752340c8f",
   "metadata": {},
   "source": [
    "# 团体时间序列\n",
    "到目前为止的故事：\n",
    "\n",
    "GroupKFold迭代器确实尊重分组：任何组都不会是两个折叠的一部分，但会打乱时间顺序\n",
    "\n",
    "TimeSeriesSplit正好相反"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d751ebf-5cb4-4c01-aa59-661327563f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  3  4  5  6  8  9 10 11]\n",
      "[ 2  7 12 17 22 27 35 40 45 49]\n",
      "[]\n",
      "---\n",
      "[ 0  2  3  4  5  7  8  9 10 12]\n",
      "[ 1  6 11 15 16 21 26 34 39 44]\n",
      "[]\n",
      "---\n",
      "[ 0  1  2  3  4  6  7  8  9 11]\n",
      "[ 5 10 20 25 30 31 32 38 43 48]\n",
      "[]\n",
      "---\n",
      "[ 1  2  3  5  6  7  8 10 11 12]\n",
      "[ 0  4  9 14 19 24 29 33 37 42]\n",
      "[]\n",
      "---\n",
      "[ 0  1  2  4  5  6  7  9 10 11]\n",
      "[ 3  8 13 18 23 28 36 41 46 51]\n",
      "[]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "for train_idx, test_idx in GroupKFold().split(xtrain, groups = pd.DataFrame(time_train)['time_id']):\n",
    "    id1 = time_train.loc[train_idx].unique()\n",
    "    id2 = time_train.loc[test_idx].unique()\n",
    "    \n",
    "    print(id1[0:10])\n",
    "    print(id2[0:10])\n",
    "    print(np.intersect1d(id1,id2))\n",
    "\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bc32314-b2ad-42ab-bf47-81f7ed565242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the notebo\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "678d9421-a319-4bfc-8a7b-d9cc35ba70a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the notebo\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class GroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"具有非重叠组的时间序列交叉验证器变体。\n",
    "    为分割时间序列数据样本提供训练/测试指标\n",
    "    根据a以固定时间间隔观察到\n",
    "    第三方提供的组。\n",
    "    在每次拆分中，测试指数必须高于以前，因此会洗牌\n",
    "    在交叉验证器中是不合适的。\n",
    "    这个交叉验证对象是：class:`KFold`的变体。\n",
    "    在第k次拆分中，它返回前k个折叠作为训练集\n",
    "    第（k+1）倍作为测试集。\n",
    "    同一组不会出现在两个不同的折叠中（\n",
    "    不同的组必须至少等于折叠数）。\n",
    "    请注意，与标准交叉验证方法不同，连续\n",
    "    训练集是之前训练集的超集。\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_size : int, default=None\n",
    "        Maximum size for a single training set.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.model_selection import GroupTimeSeriesSplit\n",
    "    >>> groups = np.array(['a', 'a', 'a', 'a', 'a', 'a',\\\n",
    "                           'b', 'b', 'b', 'b', 'b',\\\n",
    "                           'c', 'c', 'c', 'c',\\\n",
    "                           'd', 'd', 'd'])\n",
    "    >>> gtss = GroupTimeSeriesSplit(n_splits=3)\n",
    "    >>> for train_idx, test_idx in gtss.split(groups, groups=groups):\n",
    "    ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
    "    ...     print(\"TRAIN GROUP:\", groups[train_idx],\\\n",
    "                  \"TEST GROUP:\", groups[test_idx])\n",
    "    TRAIN: [0, 1, 2, 3, 4, 5] TEST: [6, 7, 8, 9, 10]\n",
    "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a']\\\n",
    "    TEST GROUP: ['b' 'b' 'b' 'b' 'b']\n",
    "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] TEST: [11, 12, 13, 14]\n",
    "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b']\\\n",
    "    TEST GROUP: ['c' 'c' 'c' 'c']\n",
    "    TRAIN: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\\\n",
    "    TEST: [15, 16, 17]\n",
    "    TRAIN GROUP: ['a' 'a' 'a' 'a' 'a' 'a' 'b' 'b' 'b' 'b' 'b' 'c' 'c' 'c' 'c']\\\n",
    "    TEST GROUP: ['d' 'd' 'd']\n",
    "    \"\"\"\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_size=None\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_size = max_train_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "        group_test_size = n_groups // n_folds\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "            for train_group_idx in unique_groups[:group_test_start]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "            train_end = train_array.size\n",
    "            if self.max_train_size and self.max_train_size < train_end:\n",
    "                train_array = train_array[train_end -\n",
    "                                          self.max_train_size:train_end]\n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6648916-5592-4d83-a5fa-7440578c0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GroupTimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e7509f1f-63b9-42e6-99fc-79e1219c8401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199\n",
      " 200 201 202 203 204 205 206]\n",
      "[]\n",
      "---\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[365 366 367 373 374 375 376 377 378 379 380 381 383 384 385 386 387 388\n",
      " 389 390 391 392 393 394 395]\n",
      "[]\n",
      "---\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572\n",
      " 573 574 575 576 577 578 579]\n",
      "[]\n",
      "---\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754\n",
      " 755 756 757 758 759 760 761]\n",
      "[]\n",
      "---\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24]\n",
      "[919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936\n",
      " 937 938 939 940 941 942 943]\n",
      "[]\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for train_idx, test_idx in GroupTimeSeriesSplit().split(xtrain, groups = pd.DataFrame(time_train)['time_id']):\n",
    "    id1 = time_train.loc[train_idx].unique()\n",
    "    id2 = time_train.loc[test_idx].unique()\n",
    "    \n",
    "    print(id1[0:25])\n",
    "    print(id2[0:25])\n",
    "    print(np.intersect1d(id1,id2))    \n",
    "    \n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97d30534-3e1f-4c20-a94a-a03b48e6a3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: -0.0487\n",
      "test score: 0.0235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0788\n",
      "test score: 0.0715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0382\n",
      "test score: 0.0286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0998\n",
      "test score: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0947\n",
      "test score: 0.0655\n"
     ]
    }
   ],
   "source": [
    "res_vec = np.zeros((CFG.nfolds, 1))\n",
    "\n",
    "for (ii, (id0, id1)) in enumerate(GroupTimeSeriesSplit().split(xtrain, groups = pd.DataFrame(time_train)['time_id'])):\n",
    "    \n",
    "    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n",
    "    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "    model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)],\n",
    "              verbose= 250, early_stopping_rounds=100)\n",
    "    \n",
    "    val_preds = model.predict(x1)\n",
    "    prv[:,ii] += model.predict(xtest) / CFG.nfolds\n",
    "    \n",
    "    # validation score    \n",
    "    score = np.round(p(val_preds, y1)[0],4)\n",
    "    res_vec[ii] = score\n",
    "    print(\"validation score: \" + str(score))\n",
    "\n",
    "    # actual test performance\n",
    "    test_preds = model.predict(xtest)\n",
    "    score = np.round(p(test_preds, ytest)[0],4)\n",
    "    print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "    del model, x0, x1, y0, y1"
   ]
  },
  {
   "cell_type": "raw",
   "id": "918b0e15-88c5-4fe7-ae3f-5e3ae18610ea",
   "metadata": {},
   "source": [
    "# 清除组时间序列¶\n",
    "正如我们上面看到的，转向分组时间序列分割可以改善这种情况。如果我们专注于这场竞争的特定领域（金融），我们可以更进一步，通过探索金融中事件时间的性质，使验证方案更接近实际情况：\n",
    "金融时间序列中的标记数据点具有交易时间和事件时间。\n",
    "事件时间=未来资产的市值达到一定水平的时间，如止损或止盈价格。\n",
    "这意味着标签变得依赖于路径，需要小心，这样在计算标签时，我们就不会看到样本外的折叠。\n",
    "\n",
    "举个具体的例子，假设我们正试图建立一个机器学习模型，根据各种数据源预测IBM价格在未来5个工作日内是上涨还是下跌至少50个基点（bps）。这些波动的规模是根据IBM股票最近的实际波动水平估算的。一个常见的标签方案是：如果股价波动超过50个基点，则为+1，如果股价绝对值波动低于50个基点则为0，如果股价下跌超过50个百分点则为-1。接下来，让我们假设我们的典型交易期限为1周。你今天会进入一个头寸，一周后清算。然而，在实践中，大多数人都会为交易设定止损或止盈水平，这样如果达到这两个水平中的任何一个，他们就可以提前退出交易。关键是，要按市值计价你的交易，你需要观察未来5天或未来5个交易点的价格走势（你可以提前退出）。\n",
    "TL；DR在标签过程中，我们必须注意删除事件时间与测试折叠中的交易时间重叠的数据。这个过程称为净化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b556639d-e7ce-48e0-b6af-8eba5a6e1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42cb224a-3608-4de9-8c4a-9ac7a670498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = PurgedGroupTimeSeriesSplit( n_splits=5,\n",
    "    max_train_group_size=15, group_gap=5, max_test_group_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4637c778-40df-4db6-b2ea-a81e0a718eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.5917\n",
      "test score: -0.0284\n",
      "validation score: -0.345\n",
      "test score: 0.0567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.3501\n",
      "test score: 0.0465\n",
      "validation score: 0.05\n",
      "test score: 0.0204\n",
      "validation score: 0.1763\n",
      "test score: 0.0393\n"
     ]
    }
   ],
   "source": [
    "res_vec = np.zeros((CFG.nfolds, 1))\n",
    "\n",
    "for (ii, (id0, id1)) in enumerate(cv.split(xtrain, groups = pd.DataFrame(time_train)['time_id'])):\n",
    "    \n",
    "    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n",
    "    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "    model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)],\n",
    "              verbose= 250, early_stopping_rounds=100)\n",
    "    \n",
    "    val_preds = model.predict(x1)\n",
    "    prv[:,ii] += model.predict(xtest) / CFG.nfolds\n",
    "    \n",
    "    # validation score    \n",
    "    score = np.round(p(val_preds, y1)[0],4)\n",
    "    res_vec[ii] = score\n",
    "    print(\"validation score: \" + str(score))\n",
    "\n",
    "    # actual test performance\n",
    "    test_preds = model.predict(xtest)\n",
    "    score = np.round(p(test_preds, ytest)[0],4)\n",
    "    print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "    del model, x0, x1, y0, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b06203db-f845-49f0-963e-469d74a889c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "from itertools import combinations\n",
    "\n",
    "class CombinatorialPurgedGroupKFold():\n",
    "    def __init__(self, n_splits = 6, n_test_splits = 2, purge = 1, pctEmbargo = 0.01, **kwargs):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_test_splits = n_test_splits\n",
    "        self.purge = purge\n",
    "        self.pctEmbargo = pctEmbargo\n",
    "        \n",
    "    def split(self, X, y = None, groups = None):\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "            \n",
    "        u, ind = np.unique(groups, return_index = True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_groups = len(unique_groups)\n",
    "        group_dict = {}\n",
    "        for idx in range(len(X)):\n",
    "            if groups[idx] in group_dict:\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "                \n",
    "        n_folds = comb(self.n_splits, self.n_test_splits, exact = True)\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "            \n",
    "        mbrg = int(n_groups * self.pctEmbargo)\n",
    "        if mbrg < 0:\n",
    "            raise ValueError(\n",
    "                \"The number of 'embargoed' groups should not be negative\")\n",
    "        \n",
    "        split_dict = {}\n",
    "        group_test_size = n_groups // self.n_splits\n",
    "        for split in range(self.n_splits):\n",
    "            if split == self.n_splits - 1:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):].tolist()\n",
    "            else:\n",
    "                split_dict[split] = unique_groups[int(split * group_test_size):int((split + 1) * group_test_size)].tolist()\n",
    "        \n",
    "        for test_splits in combinations(range(self.n_splits), self.n_test_splits):\n",
    "            test_groups = []\n",
    "            banned_groups = []\n",
    "            for split in test_splits:\n",
    "                test_groups += split_dict[split]\n",
    "                banned_groups += unique_groups[split_dict[split][0] - self.purge:split_dict[split][0]].tolist()\n",
    "                banned_groups += unique_groups[split_dict[split][-1] + 1:split_dict[split][-1] + self.purge + mbrg + 1].tolist()\n",
    "            train_groups = [i for i in unique_groups if (i not in banned_groups) and (i not in test_groups)]\n",
    "\n",
    "            train_idx = []\n",
    "            test_idx = []\n",
    "            for train_group in train_groups:\n",
    "                train_idx += group_dict[train_group]\n",
    "            for test_group in test_groups:\n",
    "                test_idx += group_dict[test_group]\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f973a74a-0707-4ed6-81a3-ebc17f298a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Fold 0\n",
      "====================================================================================================\n",
      "Train indices: [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 52\n",
      "Test Indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] Length: 12\n",
      "====================================================================================================\n",
      "Fold 1\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23] Length: 12\n",
      "====================================================================================================\n",
      "Fold 2\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35] Length: 12\n",
      "====================================================================================================\n",
      "Fold 3\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47] Length: 12\n",
      "====================================================================================================\n",
      "Fold 4\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 66, 67, 68, 69] Length: 46\n",
      "Test Indices: [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59] Length: 12\n",
      "====================================================================================================\n",
      "Fold 5\n",
      "====================================================================================================\n",
      "Train indices: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53] Length: 54\n",
      "Test Indices: [60, 61, 62, 63, 64, 65, 66, 67, 68, 69] Length: 10\n"
     ]
    }
   ],
   "source": [
    "n_splits = 6\n",
    "n_test_splits = 1\n",
    "elements = list(range(10 * (n_splits + n_test_splits)))\n",
    "groups = [element // n_splits for element in elements]\n",
    "data = pd.DataFrame({\"group\": groups, \"element\": elements})\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "for index, (train_indices, test_indices) in enumerate(kfold.split(data, groups=data[\"group\"])):\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Fold {index}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(\"Train indices:\", train_indices, \"Length:\", len(train_indices))\n",
    "    print(\"Test Indices:\", test_indices, \"Length:\", len(test_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0aa819c9-1436-405f-9d70-f2a28dae5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.061\n",
      "test score: -0.0703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0984\n",
      "test score: -0.0174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0548\n",
      "test score: 0.0358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: 0.0959\n",
      "test score: 0.0503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "D:\\anaconda\\Lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation score: -0.0073\n",
      "test score: -0.0249\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "n_test_splits = 1\n",
    "kfold = CombinatorialPurgedGroupKFold(n_splits, n_test_splits)\n",
    "\n",
    "for (ii, (id0, id1)) in enumerate(kfold.split(xtrain, groups = pd.DataFrame(time_train)['time_id'])):\n",
    "    \n",
    "    x0, x1 = xtrain.loc[id0], xtrain.loc[id1]\n",
    "    y0, y1 = ytrain.loc[id0], ytrain.loc[id1]\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMRegressor(**lgb_parameters)\n",
    "\n",
    "    model.fit(x0, y0, eval_metric='rmse', eval_set=[(x0, y0), (x1, y1)],\n",
    "              verbose= 250, early_stopping_rounds=100)\n",
    "    \n",
    "    val_preds = model.predict(x1)\n",
    "    prv[:,ii] += model.predict(xtest) / CFG.nfolds\n",
    "    \n",
    "    # validation score    \n",
    "    score = np.round(p(val_preds, y1)[0],4)\n",
    "    res_vec[ii] = score\n",
    "    print(\"validation score: \" + str(score))\n",
    "\n",
    "    # actual test performance\n",
    "    test_preds = model.predict(xtest)\n",
    "    score = np.round(p(test_preds, ytest)[0],4)\n",
    "    print(\"test score: \" + str(score))\n",
    "\n",
    "\n",
    "    del model, x0, x1, y0, y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71548a7-3049-4aa7-9cdb-f61cd7f2f72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdf0b5-4b7a-4060-bc66-cac237245c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
